---
title: Embeddings 和向量数据库
date: 2025-02-21 21:44:58
tags:
  - embedding
categories:
  - Vector Database
math: true
---

# 1. 向量数据库
**向量数据库（Vector Database）** 是一种用于存储和处理向量数据的数据库，也称为矢量数据库。在数学中，向量具有大小和方向，可通过带箭头的线段表示，其相似性或距离通常用欧式距离或余弦距离衡量。

非结构化数据（如图像、文本、音视频）可通过嵌入学习或变换转化为向量数据，存储到向量数据库中，从而实现基于语义或上下文的相似性搜索，而非传统的精确匹配查询。这种方式能够更高效地检索相关数据。

向量数据库的核心特点是**高效存储与快速检索**，通过索引技术和向量检索算法，能够在高维大数据场景下实现快速响应。此外，它不仅支持向量数据管理，还能处理传统结构化数据，并支持对向量字段和结构化字段的联合过滤检索，这对实际应用提出了更高要求。

## 1.1 向量嵌入（Vector Embeddings）

传统数据库的搜索功能依赖于索引（如 B 树、倒排索引）和精确匹配算法（如 BM25、TF-IDF），这些方法适合基于关键字的查询，但在语义搜索方面表现较弱。例如，搜索“小狗”只能返回包含“小狗”的结果，而无法关联到“柯基”或“金毛”，因为传统数据库无法理解它们之间的语义关系。为实现语义搜索，通常需要人为标注特征标签，这一过程被称为 **Feature Engineering（特征工程）**，即将原始数据转化为能更好表达问题本质的特征。

然而，当处理非结构化数据（如图像、音频、视频）时，特征数量会迅速膨胀，人工标注变得困难且低效。例如，图像可能包含颜色、形状、纹理、对象等复杂特征，而音频可能涉及音调、节奏、音色等多维信息。因此，我们需要一种自动化的方式来提取这些特征，这正是 **Vector Embedding（向量嵌入）** 的作用。

**Vector Embedding** 是通过 AI 模型（如大型语言模型 LLM）生成的高维向量，能够自动捕捉数据的多种特征。对于文本，这些特征可能包括词汇、语法、语义、情感等；对于音频，可能包括音调、节奏、音高等；对于图像，则可能涉及对象、场景、纹理等。

例如：
- 文本向量可以通过 OpenAI 的 `text-embedding-ada-002` 模型生成。
- 图像向量可以通过 `clip-vit-base-patch32` 模型生成。
- 音频向量可以通过 `wav2vec2-base-960h` 模型生成。

以文本为例，将句子 `"Your text string goes here"` 输入 `text-embedding-ada-002` 模型后，会生成一个 1536 维的向量，类似以下形式：
```
[-0.006929, -0.005336, ..., -0.024047]
```
这个向量包含了该句子的所有特征（如词汇、语法、语义等），可以存储在向量数据库中，用于后续的语义搜索。

通过 Vector Embedding，我们能够以自动化的方式提取数据的语义特征，从而实现更高效、更智能的相似性搜索和检索。

## 1.2 特征和向量

向量数据库的核心在于**相似性搜索（Similarity Search）**，但要理解相似性搜索的原理，我们需要先了解特征和向量的概念。

### 为什么我们能区分不同的事物？
在生活中，我们通过识别不同事物之间的特征来区分它们。例如，区分不同种类的小狗时，可以依据体型大小、毛发长度、鼻子长短等特征。这些特征实际上构成了一个坐标系，每种小狗都可以在这个坐标系中找到自己的位置。

- **一维特征：** 如果仅用“体型大小”作为特征，我们可以将小狗按体型从小到大排列在一条直线上（一维坐标系）。体型越大的狗越靠近坐标轴的右侧。
  
- **二维特征：** 但单靠体型可能无法区分所有狗，比如哈士奇、金毛和拉布拉多的体型非常接近。这时，我们可以引入另一个特征，如“毛发长度”，从而形成一个二维坐标系。每只狗对应一个二维坐标点，这样就能更清晰地区分它们。

- **三维及更高维度：** 如果仍然无法区分某些狗（如德牧和罗威纳犬），可以继续增加特征，比如“鼻子长短”。随着特征的增多，我们得到一个高维坐标系，每只狗在这个高维空间中都有一个唯一的坐标点。

理论上，只要特征足够多，就可以将所有事物区分开来。世间万物都可以用一个多维坐标系表示，每个事物都在这个高维特征空间中对应一个坐标点。

### 向量与相似性搜索的关系
在上述二维坐标系中，德牧和罗威纳犬的坐标非常接近，这意味着它们的特征也非常相似。向量是具有大小和方向的数学结构，因此可以用向量来表示这些特征。通过计算向量之间的距离（如欧氏距离或余弦距离），我们可以量化两个事物之间的相似度。

- **相似性测量：** 如果两个向量的距离较近，则说明它们的特征相似；如果距离较远，则说明它们的特征差异较大。这种基于向量距离的相似性测量是向量数据库实现**相似性搜索**的基础。

总结来说，特征是描述事物的不同维度，而向量则是这些特征的数学表达。通过将事物映射到高维特征空间中的向量，我们可以利用向量之间的距离来衡量它们的相似性，从而实现高效的相似性搜索。


## 1.3 相似性测量 (Similarity Measurement)

在相似性搜索中，衡量两个向量之间的相似性是核心问题。这通常通过计算向量之间的距离或相似度来实现。以下是三种常见的向量相似性算法：**欧几里得距离（Euclidean Distance）**、**余弦相似度（Cosine Similarity）** 和 **点积相似度（Dot Product Similarity）**。

### 1.3.1 欧几里得距离（Euclidean Distance）
**欧几里得距离** 是一种用于衡量两个点（或向量）之间直线距离的方法，广泛应用于几何和向量空间中。其公式如下：

$$
d(A, B) = \sqrt{\sum_{i=1}^{n} (A_i - B_i)^2}
$$


其中：

-$A$和$B$分别表示两个向量；
-$n$表示向量的维度；
-$A_i$和$B_i$分别表示向量$A$和$B$在第$i$维上的值。

#### 特点与应用场景
- **优点**：欧几里得距离能够反映向量之间的绝对距离，适合需要考虑向量长度的场景。
- **适用场景**：例如在推荐系统中，如果需要根据用户的历史行为数量（如购买次数、观看时长等）来推荐商品，则欧几里得距离是一个合适的选择，因为它不仅考虑了行为模式的相似性，还考虑了行为数量的差异。

#### 局限性
- 对于高维数据，欧几里得距离可能会受到“维度灾难”的影响，导致距离计算变得不够敏感。
- 如果只关注向量的方向而非长度，欧几里得距离可能不是最佳选择。

<img src="/images/2-向量数据库基础/euclidean_dist.webp" style="width:50%; height:auto; margin: auto; display:block;" alt="欧几里得距离示意图">


### 1.3.2 余弦相似度（Cosine Similarity）

**余弦相似度** 是一种衡量两个向量相似度的指标，通过计算两向量夹角的余弦值来判断其方向一致性。值域为 -1 到 1，其中：

- **1** 表示完全相似，
- **0** 表示不相关，
- **-1** 表示完全相反。

#### 特点
- **方向敏感**：只关注向量方向，忽略长度，适合高维数据。
- **应用场景**：广泛用于文本分析（如语义搜索、文档分类）和推荐系统。

#### 公式
$$
\text{cosine_similarity}(A, B) = \frac{\sum_{i=1}^{n} A_i \cdot B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \cdot \sqrt{\sum_{i=1}^{n} B_i^2}}
$$

#### 优点
- 忽略向量长度，适合语义相似性计算（如文本、图像）。
- 能捕捉词汇分布的相似性，无需考虑文档长度。

#### 局限性
- 如果特征强度（向量长度）对相似性判断重要，则可能不适用。

<img src="/images/2-向量数据库基础/cosine_sim.webp" style="width:50%; height:auto;margin: auto; display:block;" alt="余弦相似度示意图">


### 1.3.3 点积相似度（Dot Product Similarity）

**点积相似度** 是通过计算两个向量的点积来衡量它们的相似性。其公式如下：

$$
\text{dot_product}(A, B) = \sum_{i=1}^{n} A_i \cdot B_i
$$

#### 特点与应用场景
- **优点**：点积相似度既考虑了向量的方向，也考虑了向量的长度，因此适合需要综合衡量方向和强度的场景。
- **适用场景**：例如在推荐系统中，如果希望同时考虑用户行为的模式和行为的数量，则点积相似度是一个不错的选择。

#### 局限性
- 点积相似度的结果受向量长度的影响较大，可能导致长向量对结果的主导作用过强。


## 1.4 相似性搜索 (Similarity Search)

通过比较向量之间的距离，我们可以判断它们的相似度。但在海量数据中找到与某个向量最相似的向量，逐一比较所有向量的计算成本非常高。因此，我们需要高效的算法来优化这一过程。

高效搜索算法的核心思想主要有两点：

1. **减少向量大小**：通过降维或简化向量表示来降低计算复杂度。
2. **缩小搜索范围**：利用聚类、树形结构或图形结构组织数据，将搜索限制在最相关的部分（如最近的簇或分支）。


### 1.4.1 K-Means

K-Means 是一种常用的聚类算法，能够将向量数据划分为若干个簇（clusters），从而为相似性搜索提供高效的解决方案。通过减少搜索范围，K-Means 能显著提升搜索效率。

<img src="/images/2-向量数据库基础/k-means.webp" style="width:50%; height:auto;margin: auto; display:block;" alt="k-means示意图">

#### 工作原理
K-Means 的核心思想是将数据点分配到最近的聚类中心，并不断调整这些中心的位置，直到达到稳定状态。具体步骤如下：

1. **初始化**：随机选择$k$个点作为初始聚类中心。
2. **分配**：将每个向量分配给离它最近的聚类中心，形成$k$个簇。
3. **更新**：重新计算每个簇的聚类中心（即簇内所有向量的平均值）。
4. **迭代**：重复“分配”和“更新”步骤，直到聚类中心不再变化或达到最大迭代次数。

#### 优点
- **高效性**：通过聚类，只需计算查询向量与每个聚类中心的距离，而无需与所有向量逐一比较，大幅减少计算量。
- **适用性**：特别适合处理大规模数据集，能显著加快相似性搜索速度。

#### 缺点
- **边界问题**：如果查询向量位于两个簇的边界区域，可能会遗漏最相似的向量。
- **对初始中心敏感**：初始聚类中心的选择会影响最终结果，可能导致局部最优解。
- **固定簇数**：需要预先指定簇的数量$k$，可能不适合某些动态场景。

#### 应用场景
K-Means 广泛应用于数据挖掘、图像分割、推荐系统等领域，尤其在需要快速搜索相似项的场景中表现优异。




### 1.4.2 Hierarchical Navigable Small Worlds (HNSW)
除了聚类以外，也可以通过构建树或者构建图的方式来实现近似最近邻搜索。这种方法的基本思想是每次将向量加到数据库中的时候，就先找到与它最相邻的向量，然后将它们连接起来，这样就构成了一个图。当需要搜索的时候，就可以从图中的某个节点开始，不断的进行最相邻搜索和最短路径计算，直到找到最相似的向量。

这种算法能保证搜索的质量，但是如果图中所以的节点都以最短的路径相连，如图中最下面的一层，那么在搜索的时候，就同样需要遍历所有的节点。

<img src="/images/2-向量数据库基础/vector_search.webp" style="width:50%; height:auto;margin: auto; display:block;" alt="vector search 示意图">

解决这个问题的思路与常见的跳表算法相似，如下图要搜索跳表，从最高层开始，沿着具有最长 “跳过” 的边向右移动。如果发现当前节点的值大于要搜索的值 - 我们知道已经超过了目标，因此我们会在下一级中向前一个节点。

<img src="/images/2-向量数据库基础/layers.webp" style="width:50%; height:auto;margin: auto; display:block;" alt="layers 示意图">


<img src="/images/2-向量数据库基础/skip_list_search.gif" style="width:50%; height:auto;margin: auto; display:block;" alt="skip list search 示意图">


HNSW 继承了相同的分层格式，最高层具有更长的边缘（用于快速搜索），而较低层具有较短的边缘（用于准确搜索）。

具体来说，可以将图分为多层，每一层都是一个小世界，图中的节点都是相互连接的。而且每一层的节点都会连接到上一层的节点，当需要搜索的时候，就可以从第一层开始，因为第一层的节点之间距离很长，可以减少搜索的时间，然后再逐层向下搜索，又因为最下层相似节点之间相互关联，所以可以保证搜索的质量，能够找到最相似的向量。

HNSW 算法是一种经典的空间换时间的算法，它的搜索质量和搜索速度都比较高，但是它的内存开销也比较大，因为不仅需要将所有的向量都存储在内存中。还需要维护一个图的结构，也同样需要存储。所以这类算法需要根据实际的场景来选择。

**通过一个简单的例子来说明 HNSW 的工作原理。**

假设我们有以下五个二维向量：

+ $A = (1, 2)$
+ $B = (2, 3)$
+ $C = (3, 4)$
+ $D = (8, 9)$
+ $E = (9, 10)$

我们要使用 HNSW 来找到与查询向量 $Q = (2, 2)$ 最相似的向量。

**构建阶段**

1. **初始化**：
    - 首先，我们为每个向量随机选择其在 HNSW 中的层数。例如，假设：
        * $A$ 在第2层和第1层
        * $B$ 在第1层
        * $C$ 在第1层
        * $D$ 在第1层
        * $E$ 在第1层
2. **构建图**：
    - 从最高层开始构建，$A$是第2层唯一的节点。
    - 在第1层，所有节点都存在。我们通过计算欧氏距离来连接节点，确保每个节点只连接到几个最近的邻居。

**搜索阶段**

1. **从最高层开始搜索**：
    - 从第2层的$A$开始，计算$Q$与$A$的距离：$d(Q, A) = \sqrt{(2-1)^2 + (2-2)^2} = 1$。
    - 因为$A$是唯一的节点，直接进入下一层。
2. **在第1层搜索**：
    - 从$A$开始，计算$Q$ 与$B$、$C$、$D$、$E$ 的距离：
        * $d(Q, B) = \sqrt{(2-2)^2 + (2-3)^2} = 1$
        * $d(Q, C) = \sqrt{(2-3)^2 + (2-4)^2} = \sqrt{5}$
        * $d(Q, D) = \sqrt{(2-8)^2 + (2-9)^2} = \sqrt{85}$
        * $d(Q, E) = \sqrt{(2-9)^2 + (2-10)^2} = \sqrt{113}$
    -$B$是最近的邻居。
3. **返回结果**：
    - 在第2层找到的最近邻是 $A$，第1层找到的最近邻是 $B$，即与查询向量 $Q$ 最相似的向量。

**总结**

通过这种层次化的搜索过程，HNSW 能够快速缩小搜索范围，在大规模数据中高效找到近似最近邻。

## 2. 基于 Embedding 的问答助手和意图匹配
### 2.1 Embedding models(嵌入模型)
Embeddings类是一个专为与文本嵌入模型进行交互而设计的类。有许多嵌入模型提供商（如OpenAI、Cohere、Hugging Face等）- 这个类旨在为它们提供一个标准接口。

Embeddings类会为文本创建一个向量表示。这很有用，因为这意味着我们可以在向量空间中思考文本，并做一些类似语义搜索的事情，比如在向量空间中寻找最相似的文本片段。

LangChain中的基本Embeddings类提供了两种方法：一个用于嵌入文档，另一个用于嵌入查询。前者`.embed_documents`接受多个文本作为输入，而后者`.embed_query`接受单个文本。之所以将它们作为两个单独的方法，是因为一些嵌入提供商对文档（要搜索的文档）和查询（搜索查询本身）有不同的嵌入方法。

`.embed_query`将返回一个浮点数列表，而`.embed_documents`将返回一个浮点数列表的列表。

![](https://cdn.nlark.com/yuque/0/2024/png/2424104/1722780976370-0672d8a6-e5e4-4a60-b303-11913514d81d.png)

### 2.2 设置
+ OpenAI

首先，我们需要安装OpenAI合作伙伴包：

```bash
pip install langchain-openai
```

访问API需要一个API密钥，您可以通过创建帐户并转到[这里](https://platform.openai.com/account/api-keys)来获取它。一旦我们有了密钥，我们希望通过运行以下命令将其设置为环境变量：

```bash
export OPENAI_API_KEY="..."
```

如果您不想设置环境变量，可以在初始化OpenAI LLM类时通过`api_key`命名参数直接传递密钥：

```python
from langchain_openai import OpenAIEmbeddings
embeddings_model = OpenAIEmbeddings(api_key="...")
```

否则，您可以不带任何参数初始化：

```python
from langchain_openai import OpenAIEmbeddings
embeddings_model = OpenAIEmbeddings()
```



### 2.3 嵌入文本列表(embed_documents)
使用`.embed_documents`来嵌入一个字符串列表，恢复一个嵌入列表：

```python
#示例：embed_documents.py
embeddings = embeddings_model.embed_documents(
    [
        "嗨！",
        "哦，你好！",
        "你叫什么名字？",
        "我的朋友们叫我World",
        "Hello World！"
    ]
)
len(embeddings), len(embeddings[0])
```

```plain
(5, 1536)
```

### 2.4 嵌入单个查询(embed_query)
使用`.embed_query`来嵌入单个文本片段（例如，用于与其他嵌入的文本片段进行比较）。

```python
#示例：embed_query.py
embedded_query = embeddings_model.embed_query("对话中提到的名字是什么？")
embedded_query[:5]
```

```plain
[0.003292066277936101, -0.009463472291827202, 0.03418809175491333, -0.0011715596774592996, -0.015508134849369526]
```

---

### 2.5 问答助手
```python
#示例：embed_search.py
from openai import OpenAI
#pip install numpy
from numpy import dot
from numpy.linalg import norm

client = OpenAI()


# 定义调用 Embedding API 的函数
def get_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding


# 计算余弦相似度，参考文章：https://blog.csdn.net/Hyman_Qiu/article/details/137743190
#定义一个函数 cosine_similarity，该函数接受两个向量 vec1 和 vec2 作为输入。
def cosine_similarity(vec1, vec2):
    #计算并返回两个向量之间的余弦相似度，公式为：两个向量的点积除以它们范数的乘积。
    return dot(vec1, vec2) / (norm(vec1) * norm(vec2))

# 实现文本搜索功能
# 定义一个函数 search_documents，该函数接受一个查询字符串 query 和一个文档列表 documents 作为输入。
def search_documents(query, documents):
    # 调用 get_embedding 函数生成查询字符串的嵌入向量 query_embedding。
    query_embedding = get_embedding(query)
    # 对每个文档调用 get_embedding 函数生成文档的嵌入向量，存储在 document_embeddings 列表中。
    document_embeddings = [get_embedding(doc) for doc in documents]
    # 计算查询嵌入向量与每个文档嵌入向量之间的余弦相似度，存储在 similarities 列表中
    similarities = [cosine_similarity(query_embedding, doc_embedding) for doc_embedding in document_embeddings]
    # 找到相似度最高的文档的索引 most_similar_index。
    most_similar_index = similarities.index(max(similarities))
    # 返回相似度最高的文档和相似度得分。
    return documents[most_similar_index], max(similarities)


# 测试文本搜索功能
if __name__ == "__main__":
    documents = [
        "OpenAI的ChatGPT是一个强大的语言模型。",
        "天空是蓝色的,阳光灿烂。",
        "人工智能正在改变世界。",
        "Python是一种流行的编程语言。"
    ]
    #".././resource/knowledge.txt" 文件内容，转换为上述documents
    #documents = [line.strip() for line in open(".././resource/knowledge.txt", "r", encoding="utf-8")]

    query = "天空是什么颜色的？"

    most_similar_document, similarity_score = search_documents(query, documents)
    print(f"最相似的文档: {most_similar_document}")
    print(f"相似性得分: {similarity_score}")

```



```plain
最相似的文档: 天空是蓝色的,阳光灿烂。
相似性得分: 0.9166142096488017
```

### 2.6 意图匹配
```python
#示例：embed_intention_recognition.py
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings

# 数据导入
loader = TextLoader(".././resource/qa.txt", encoding="UTF-8")
docs = loader.load()
# 数据切分
text_splitter = RecursiveCharacterTextSplitter()
documents = text_splitter.split_documents(docs)
# 创建embedding
embeddings = OpenAIEmbeddings()
# 通过向量数据库存储
vector = FAISS.from_documents(documents, embeddings)
# 查询检索
# 创建 prompt
prompt = ChatPromptTemplate.from_template("""仅根据提供的上下文回答以下问题：:
<context>
{context}
</context>
Question: {input}""")
# 创建模型
llm = ChatOpenAI()
# 创建 document 的chain， 查询
document_chain = create_stuff_documents_chain(llm, prompt)
from langchain.chains import create_retrieval_chain

# # 创建搜索chain 返回值为 VectorStoreRetriever
retriever = vector.as_retriever()
retrieval_chain = create_retrieval_chain(retriever, document_chain)
# # 执行请求
response = retrieval_chain.invoke({"input": "天气"})
print(response["answer"])

```



```python
抱歉，我无法回答关于天气的问题。如果您需要查询天气信息，请使用天气应用程序或者访问天气网站。我可以帮您订餐、播放音乐、设置闹钟或者讲笑话。有什么其他问题我可以帮助您解决吗？
```



## 3. 基于 LangChain 构建向量存储和查询：Chroma, Weaviate, Qdrant,  Milvus
### 3.1 Vector stores(向量存储)
存储和搜索非结构化数据的最常见方法之一是将其嵌入并存储生成的嵌入向量， 然后在查询时将非结构化查询嵌入并检索与嵌入查询“最相似”的嵌入向量。 向量存储会处理存储嵌入数据并为您执行向量搜索。 可以通过以下方式将向量存储转换为检索器接口：



Retrievers(检索器)是一个接口，根据非结构化查询返回文档。 它比向量存储更通用。 检索器不需要能够存储文档，只需要能够返回（或检索）它们。 检索器可以从向量存储器创建，但也足够广泛，包括Wikipedia搜索和Amazon Kendra。 检索器接受字符串查询作为输入，并返回文档列表作为输出。

```python
vectorstore = MyVectorStore()
retriever = vectorstore.as_retriever()
```



### 3.2 Chroma
官方文档：[https://docs.trychroma.com/](https://docs.trychroma.com/)

[Chroma](https://docs.trychroma.com/getting-started) ( /'kromə/ n. （色彩的）浓度，色度 )是一个以人工智能为基础的开源向量数据库，专注于开发者的生产力和幸福感。Chroma 使用 Apache 2.0 许可证。 使用以下命令安装 Chroma：

```plain
pip install langchain-chroma
```

Chroma 可以以多种模式运行。以下是每种模式的示例，均与 LangChain 集成：

+ `in-memory` - 在 Python 脚本或 Jupyter 笔记本中
+ `in-memory with persistance` - 在脚本或笔记本中保存/加载到磁盘
+ `in a docker container` - 作为在本地机器或云中运行的服务器

与任何其他数据库一样，您可以进行以下操作：

+ `.add`
+ `.get`
+ `.update`
+ `.upsert`
+ `.delete`
+ `.peek`
+ 而 `.query` 则运行相似性搜索。

查看完整文档，请访问 [docs](https://docs.trychroma.com/reference/Collection)。要直接访问这些方法，可以使用 `._collection.method()`。

#### 基本示例
在这个基本示例中，我们获取《乔布斯演讲稿》，将其分割成片段，使用开源嵌入模型进行嵌入，加载到 Chroma 中，然后进行查询。

```python
#示例：chroma_base.py
# pip install langchain-chroma
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
# pip install -U langchain-huggingface
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import CharacterTextSplitter

# 加载文档并将其分割成片段
loader = TextLoader("../../resource/knowledge.txt", encoding="UTF-8")
documents = loader.load()
# 将其分割成片段
text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)
docs = text_splitter.split_documents(documents)
# 创建开源嵌入函数
embedding_function = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
# 将其加载到 Chroma 中
db = Chroma.from_documents(docs, embedding_function)
# 进行查询
query = "Pixar公司是做什么的?"
docs = db.similarity_search(query)
# 打印结果
print(docs[0].page_content)
```

```plain
During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。
```

#### 基本示例（包括保存到磁盘）
在上一个示例的基础上，如果您想要保存到磁盘，只需初始化 Chroma 客户端并传递要保存数据的目录。

`注意`：Chroma 尽最大努力自动将数据保存到磁盘，但多个内存客户端可能会相互干扰。最佳做法是，任何给定时间只运行一个客户端。

```python
#示例：chroma_disk.py

# 保存到磁盘
db2 = Chroma.from_documents(docs, embedding_function, persist_directory="./chroma_db")
docs = db2.similarity_search(query)
# 从磁盘加载
db3 = Chroma(persist_directory="./chroma_db", embedding_function=embedding_function)
docs = db3.similarity_search(query)
print(docs[0].page_content)
```

```plain
During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。
```

#### 将 Chroma 客户端传递给 Langchain
您还可以创建一个 Chroma 客户端并将其传递给 LangChain。如果您希望更轻松地访问底层数据库，这将特别有用。

您还可以指定要让 LangChain 使用的集合名称。

```python
#示例：chroma_client.py
import chromadb
persistent_client = chromadb.PersistentClient()
collection = persistent_client.get_or_create_collection("collection_name")
collection.add(ids=["1", "2", "3"], documents=["a", "b", "c"])
langchain_chroma = Chroma(
    client=persistent_client,
    collection_name="collection_name",
    embedding_function=embedding_function,
)
print("在集合中有", langchain_chroma._collection.count(), "个文档")
```

```plain
Insert of existing embedding ID: 1
Insert of existing embedding ID: 2
Insert of existing embedding ID: 3
Add of existing embedding ID: 1
Add of existing embedding ID: 2
Add of existing embedding ID: 3
在集合中有 3 个项目

```

#### 更新和删除
在构建真实应用程序时，您不仅希望添加数据，还希望更新和删除数据。

Chroma 要求用户提供 `ids` 来简化这里的簿记工作。`ids` 可以是文件名，也可以是类似 `filename_paragraphNumber` 的组合哈希值。

Chroma 支持所有这些操作，尽管有些操作仍在通过 LangChain 接口进行整合。额外的工作流改进将很快添加。

以下是一个基本示例，展示如何执行各种操作：

```python
#示例：chroma_update.py
# pip install langchain-chroma
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
# pip install -U langchain-huggingface
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import CharacterTextSplitter

# 加载文档并将其分割成片段
loader = TextLoader("../../resource/knowledge.txt", encoding="UTF-8")
documents = loader.load()
# 将其分割成片段
text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)
docs = text_splitter.split_documents(documents)
# 创建开源嵌入函数
embedding_function = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
query = "Pixar公司是做什么的?"
# 创建简单的 ids
ids = [str(i) for i in range(1, len(docs) + 1)]
# 添加数据
example_db = Chroma.from_documents(docs, embedding_function, ids=ids)
docs = example_db.similarity_search(query)
# 更新文档的元数据
docs[0].metadata = {
    "source": "../../resource/knowledge.txt",
    "new_value": "hello world",
}
print("更新前内容：")
print(example_db._collection.get(ids=[ids[0]]))
example_db.update_document(ids[0], docs[0])
print("更新后内容：")
print(example_db._collection.get(ids=[ids[0]]))
# 删除最后一个文档
print("删除前计数", example_db._collection.count())
print(example_db._collection.get(ids=[ids[-1]]))
example_db._collection.delete(ids=[ids[-1]])
print("删除后计数", example_db._collection.count())
print(example_db._collection.get(ids=[ids[-1]]))
```

```markdown
更新前内容：
{'ids': ['1'], 'embeddings': None, 'metadatas': [{'source': '../../resource/knowledge.txt'}], 'documents': ["\ufeffI am honored to be with you today at your commencement from one of the finest universities in the world. I never graduated from college. Truth be told, this is the closest I've ever gotten to a college graduation. Today I want to tell you three stories from my life. That's it. No big deal. Just three stories.\n我今天很荣幸能和你们一起参加毕业典礼，斯坦福大学是世界上最好的大学之一。我从来没有从大学中毕业。说实话,今天也许是在我的生命中离大学毕业最近的一天了。今天我想向你们讲述我生活中的三个故事。不是什么大不了的事情,只是三个故事而已。\n\nThe first story is about connecting the dots.\n第一个故事是关于如何把生命中的点点滴滴串连起来。\n\nI dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit. So why did I drop out?\n我在Reed大学读了六个月之后就退学了，但是在十八个月以后——我真正的作出退学决定之前，我还经常去学校。我为什么要退学呢？"], 'uris': None, 'data': None, 'included': ['metadatas', 'documents']}
更新后内容：
{'ids': ['1'], 'embeddings': None, 'metadatas': [{'new_value': 'hello world', 'source': '../../resource/knowledge.txt'}], 'documents': ["During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.\n在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。"], 'uris': None, 'data': None, 'included': ['metadatas', 'documents']}
删除前计数 16
{'ids': ['16'], 'embeddings': None, 'metadatas': [{'source': '../../resource/knowledge.txt'}], 'documents': ['Stewart and his team put out several issues of The Whole Earth Catalog, and then when it had run its course, they put out a final issue. It was the mid-1970s, and I was your age. On the back cover of their final issue was a photograph of an early morning country road, the kind you might find yourself hitchhiking on if you were so adventurous. Beneath it were the words: "Stay Hungry. Stay Foolish." It was their farewell message as they signed off. Stay Hungry. Stay Foolish. And I have always wished that for myself. And now, as you graduate to begin anew, I wish that for you.\nStewart和他的伙伴出版了几期的“整个地球的目录”，当它完成了自己使命的时候，他们做出了最后一期的目录。那是在七十年代的中期，你们的时代。在最后一期的封底上是清晨乡村公路的照片（如果你有冒险精神的话，你可以自己找到这条路的），在照片之下有这样一段话：“求知若饥，虚心若愚。”这是他们停止了发刊的告别语。“求知若饥，虚心若愚。”我总是希望自己能够那样，现在，在你们即将毕业，开始新的旅程的时候，我也希望你们能这样：\n\nStay Hungry. Stay Foolish.\n求知若饥，虚心若愚。\n\nThank you all very much.\n非常感谢你们。'], 'uris': None, 'data': None, 'included': ['metadatas', 'documents']}
删除后计数 15
{'ids': [], 'embeddings': None, 'metadatas': [], 'documents': [], 'uris': None, 'data': None, 'included': ['metadatas', 'documents']}
```



#### 使用 OpenAI Embeddings
许多人喜欢使用 OpenAIEmbeddings，以下是如何设置它。

```python
#示例：chroma_openai.py
from langchain_openai import OpenAIEmbeddings
# pip install langchain-chroma
from langchain_chroma import Chroma
import chromadb
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader

embeddings = OpenAIEmbeddings()
persistent_client = chromadb.PersistentClient()
new_client = chromadb.EphemeralClient()
# 加载文档并将其分割成片段
loader = TextLoader("../../resource/knowledge.txt", encoding="UTF-8")
documents = loader.load()
# 将其分割成片段
text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

openai_lc_client = Chroma.from_documents(
    docs, embeddings, client=new_client, collection_name="openai_collection"
)
query = "Pixar公司是做什么的?"
docs = openai_lc_client.similarity_search(query)
print(docs[0].page_content)

```

```plain
During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。
```

---

#### 其他功能
##### 带分数的相似性搜索
返回的距离分数是余弦距离。因此，分数越低越好。

```python
#示例：chroma_other.py
docs = db.similarity_search_with_score(query)
```

```python
docs[0]
#0.8513926863670349
```

```plain
(Document(metadata={'source': '../../resource/knowledge.txt'}, page_content="During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.\n在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。"), 0.8513926863670349)
```

##### 检索器选项
本节介绍如何在检索器中使用 Chroma 的不同选项。

**MMR**

除了在检索器对象中使用相似性搜索外，还可以使用 MMR（Maximal Marginal Relevance，最大边际相关性）是一种信息检索和文本摘要技术，用于在选择文档或文本片段时平衡相关性和多样性。其主要目的是在检索结果中既包含与查询高度相关的内容，又避免结果之间的高度冗余。

**MMR的作用**

1. 提高结果的多样性：通过引入多样性，MMR可以避免检索结果中出现重复信息，从而提供更全面的答案。
2. 平衡相关性和新颖性：MMR在选择结果时，既考虑与查询的相关性，也考虑新信息的引入，以确保结果的多样性和覆盖面。
3. 减少冗余：通过避免选择与已选结果高度相似的文档，MMR可以减少冗余，提高信息的利用效率。

**在检索器对象中使用MMR**

在使用向量检索器（如FAISS）时，通常通过相似性搜索来查找与查询最相关的文档。然而，这种方法有时可能会返回许多相似的结果，导致信息冗余。MMR可以在这种情况下发挥作用，通过以下步骤实现：

1. 计算相关性：首先，计算每个候选文档与查询的相似性得分。
2. 计算多样性：然后，计算每个候选文档与已选文档集合的相似性得分。
3. 选择文档：在每一步选择一个文档，使得该文档在相关性和多样性之间达到最佳平衡。

```python
#示例：chroma_other.py
retriever = db.as_retriever(search_type="mmr")
```

```python
retriever.invoke(query)[0]
```

```plain
page_content='During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。' metadata={'source': '../../resource/knowledge.txt'}
```



### Weaviate
如何使用 `langchain-weaviate` 包在 LangChain 中开始使用 Weaviate 向量存储。

[Weaviate](https://weaviate.io/) 是一个开源的向量数据库。它允许您存储来自您喜爱的机器学习模型的数据对象和向量嵌入，并能够无缝地扩展到数十亿个数据对象。

官方文档：[https://weaviate.io/developers/weaviate](https://weaviate.io/developers/weaviate)

要使用此集成，您需要运行一个 Weaviate 数据库实例。

#### 最低版本
此模块需要 Weaviate `1.23.7` 或更高版本。但是，我们建议您使用最新版本的 Weaviate。

#### 连接到 Weaviate
在本文中，我们假设您在 `http://localhost:8080` 上运行了一个本地的 Weaviate 实例，并且端口 50051 用于 [gRPC 通信](https://weaviate.io/blog/grpc-performance-improvements)。因此，我们将使用以下代码连接到 Weaviate：

```python
weaviate_client = weaviate.connect_to_local()
```

##### 其他部署选项
Weaviate 可以以许多不同的方式进行[部署](https://weaviate.io/developers/weaviate/starter-guides/which-weaviate)，例如使用[Weaviate Cloud Services (WCS)](https://console.weaviate.cloud/)、[Docker](https://weaviate.io/developers/weaviate/installation/docker-compose)或[Kubernetes](https://weaviate.io/developers/weaviate/installation/kubernetes)。

如果您的 Weaviate 实例以其他方式部署，可以在[此处阅读更多信息](https://weaviate.io/developers/weaviate/client-libraries/python#instantiate-a-client)关于连接到 Weaviate 的不同方式。您可以使用不同的[辅助函数](https://weaviate.io/developers/weaviate/client-libraries/python#python-client-v4-helper-functions)，或者[创建一个自定义实例](https://weaviate.io/developers/weaviate/client-libraries/python#python-client-v4-explicit-connection)。

请注意，您需要一个 `v4` 客户端 API，它将创建一个 `weaviate.WeaviateClient` 对象。

##### 认证
一些 Weaviate 实例，例如在 WCS 上运行的实例，启用了认证，例如 API 密钥和/或用户名+密码认证。

阅读[客户端认证指南](https://weaviate.io/developers/weaviate/client-libraries/python#authentication)以获取更多信息，以及[深入的认证配置页面](https://weaviate.io/developers/weaviate/configuration/authentication)。

#### 安装
```python
# 安装包
# %pip install -Uqq langchain-weaviate
# %pip install openai tiktoken langchain
```

#### 环境设置
本文使用 `OpenAIEmbeddings` 通过 OpenAI API。我们建议获取一个 OpenAI API 密钥，并将其作为名为 `OPENAI_API_KEY` 的环境变量导出。

完成后，您的 OpenAI API 密钥将被自动读取。如果您对环境变量不熟悉，可以在[此处](https://docs.python.org/3/library/os.html#os.environ)或[此指南](https://www.twilio.com/en-us/blog/environment-variables-python)中阅读更多关于它们的信息。

配置Weaviate的WCD_DEMO_URL和WCD_DEMO_RO_KEY

```powershell
setx WCD_DEMO_URL ""
setx WCD_DEMO_RO_KEY ""
```

![](https://cdn.nlark.com/yuque/0/2024/png/2424104/1724049541827-43f841c0-1312-41fa-997c-aaf5d12c74ca.png)

### 用法
#### 通过相似性查找对象
以下是一个示例，演示如何通过查询查找与之相似的对象，从数据导入到查询 Weaviate 实例。

##### 步骤 1：数据导入
首先，我们将创建要添加到 `Weaviate` 的数据，方法是加载并分块长文本文件的内容。

```python
from langchain_community.document_loaders import TextLoader
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
```

现在，我们可以导入数据。要这样做，连接到 Weaviate 实例，并使用生成的 `weaviate_client` 对象。例如，我们可以将文档导入如下所示：

```python
#示例：weaviate_client.py
weaviate_client = weaviate.connect_to_weaviate_cloud(
    cluster_url=wcd_url,  # Replace with your Weaviate Cloud URL
    auth_credentials=Auth.api_key(wcd_api_key),  # Replace with your Weaviate Cloud key
    headers={'X-OpenAI-Api-key': openai_api_key}  # Replace with your OpenAI API key
)
db = WeaviateVectorStore.from_documents(docs, embeddings, client=weaviate_client)
```

##### 第二步：执行搜索
现在我们可以执行相似度搜索。这将返回与查询文本最相似的文档，基于存储在 Weaviate 中的嵌入和从查询文本生成的等效嵌入。

```python
#示例：weaviate_search.py
# pip install -Uqq langchain-weaviate
# pip install openai tiktoken langchain
import os
import weaviate
from langchain_community.document_loaders import TextLoader
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
from langchain_weaviate.vectorstores import WeaviateVectorStore
from weaviate.classes.init import Auth

embeddings = OpenAIEmbeddings()
# 加载文档并将其分割成片段
loader = TextLoader("../../resource/knowledge.txt", encoding="UTF-8")
documents = loader.load()
# 将其分割成片段
text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

# Best practice: store your credentials in environment variables
wcd_url = os.environ["WCD_DEMO_URL"]
wcd_api_key = os.environ["WCD_DEMO_RO_KEY"]
openai_api_key = os.environ["OPENAI_API_KEY"]

weaviate_client = weaviate.connect_to_weaviate_cloud(
    cluster_url=wcd_url,  # Replace with your Weaviate Cloud URL
    auth_credentials=Auth.api_key(wcd_api_key),  # Replace with your Weaviate Cloud key
    headers={'X-OpenAI-Api-key': openai_api_key}  # Replace with your OpenAI API key
)
db = WeaviateVectorStore.from_documents(docs, embeddings, client=weaviate_client)
query = "Pixar公司是做什么的?"
docs = db.similarity_search(query)
print(docs[0].page_content)
weaviate_client.close()
```

```plain
During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。
```

##### 量化结果相似性
您可以选择检索相关性“分数”。这是一个相对分数，表示特定搜索结果在搜索结果池中的好坏程度。

请注意，这是相对分数，意味着不应用于确定相关性的阈值。但是，它可用于比较整个搜索结果集中不同搜索结果的相关性。

```python
#示例：weaviate_similarity.py
query = "Pixar公司是做什么的?"
docs = db.similarity_search_with_score(query, k=5)
for doc in docs:
    print(f"{doc[1]:.3f}", ":", doc[0].page_content[:100] + "...")
```

```plain
0.700 : During the next five years, I started a company named NeXT, another company named Pixar, and fell in...
0.337 : I was lucky – I found what I loved to do early in life. Woz and I started Apple in my parents garage...
0.271 : I really didn't know what to do for a few months. I felt that I had let the previous generation of e...
0.256 : I'm pretty sure none of this would have happened if I hadn't been fired from Apple. It was awful tas...
0.191 : Stewart and his team put out several issues of The Whole Earth Catalog, and then when it had run its...
```


#### Qdrant
##### Qdrant介绍
[Qdrant](https://qdrant.tech/documentation/)（读作：quadrant  /'kwɑdrənt/  n. 象限；象限仪；四分之一圆）是一个向量相似度搜索引擎。它提供了一个生产就绪的服务，具有方便的 API 来存储、搜索和管理点 - 带有附加载荷的向量。`Qdrant`专门支持扩展过滤功能，使其对各种神经网络或基于语义的匹配、分面搜索和其他应用非常有用。

官方文档：[https://qdrant.tech/documentation/](https://qdrant.tech/documentation/)

以下展示了如何使用与`Qdrant`向量数据库相关的功能。

有各种运行`Qdrant`的模式，取决于所选择的模式，会有一些细微的差异。选项包括：

+ 本地模式，无需服务器
+ Qdrant 云

请参阅[安装说明](https://qdrant.tech/documentation/install/)。

```python
%pip install --upgrade --quiet  langchain-qdrant langchain-openai langchain
```

```python
#示例：qdrant_local.py
from langchain_community.document_loaders import TextLoader
from langchain_openai import OpenAIEmbeddings
from langchain_qdrant import Qdrant
from langchain_text_splitters import CharacterTextSplitter
```

```python
loader = TextLoader("../../resource/knowledge.txt", encoding="UTF-8")
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)
docs = text_splitter.split_documents(documents)
embeddings = OpenAIEmbeddings()
```

#### 本地模式
Python 客户端允许您在本地模式下运行相同的代码，而无需运行 Qdrant 服务器。这对于测试和调试或者如果您计划仅存储少量向量非常有用。嵌入可能完全保存在内存中或者持久化在磁盘上。

##### 内存中
对于一些测试场景和快速实验，您可能更喜欢仅将所有数据保存在内存中，因此当客户端被销毁时数据会丢失 - 通常在脚本/笔记本的末尾。

```python
#示例：qdrant_local.py
qdrant = Qdrant.from_documents(
    docs,
    embeddings,
    location=":memory:",  # 本地模式，仅内存存储
    collection_name="my_documents",
)
```

##### 磁盘存储
在不使用 Qdrant 服务器的本地模式下，还可以将您的向量存储在磁盘上，以便它们在运行之间持久化。

```python
#示例：qdrant_disk.py
qdrant = Qdrant.from_documents(
    docs,
    embeddings,
    path="/tmp/local_qdrant",
    collection_name="my_documents",
)
```

#### 相似度搜索
使用 Qdrant 向量存储的最简单场景是执行相似度搜索。在幕后，我们的查询将使用`embedding_function`对查询进行编码，并用于在 Qdrant 集合中查找相似的文档。

```python
query = "Pixar公司是做什么的?"
found_docs = qdrant.similarity_search(query)
```

```python
print(found_docs[0].page_content)
```

```plain
During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。
```

 

#### Qdrant 云
如果您不想忙于管理基础设施，可以选择在 [Qdrant 云](https://cloud.qdrant.io/)上设置一个完全托管的 Qdrant 集群。包括一个永久免费的 1GB 集群供试用。使用托管版本与使用 Qdrant 的主要区别在于，您需要提供 API 密钥以防止公开访问您的部署。该值也可以设置在 `QDRANT_API_KEY` 环境变量中。

```python
url = "<---qdrant cloud cluster url here --->"
api_key = "<---api key here--->"
qdrant = Qdrant.from_documents(
    docs,
    embeddings,
    url=url,
    prefer_grpc=True,
    api_key=api_key,
    collection_name="my_documents",
)
```



### Milvus
#### [Milvus](https://milvus.io/docs/overview.md)介绍
[Milvus](https://milvus.io/docs/overview.md) 是一个数据库，用于存储、索引和管理由深度神经网络和其他机器学习（ML）模型生成的大规模嵌入向量。

官方文档：[https://milvus.io/docs/overview.md](https://milvus.io/docs/overview.md)

下面讲解如何使用与 Milvus 向量数据库相关的功能。

配置环境变量MILVUS_API_URL和MILVUS_API_KEY

```powershell
setx MILVUS_API_URL ""
setx MILVUS_API_KEY ""
```

zilliz：[https://cloud.zilliz.com/](https://cloud.zilliz.com/)

![](https://cdn.nlark.com/yuque/0/2024/png/2424104/1724049217804-83fe8bbd-04c9-4fb6-9793-89e9befba746.png)

要运行，您应该已经启动并运行了一个[Milvus 实例](https://milvus.io/docs/install_standalone-docker.md)。

```python
#示例：milvus_zilliz.py
#pip install --upgrade --quiet  pymilvus
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import Milvus
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader
loader = TextLoader("../../resource/knowledge.txt", encoding="UTF-8")
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)
docs = text_splitter.split_documents(documents)
embeddings = OpenAIEmbeddings()
```

```python
vector_db = Zilliz.from_documents(  # or Milvus.from_documents
    docs,
    embeddings,
    #存储到collection_1中
    collection_name="collection_1",
    connection_args={"uri": os.getenv("MILVUS_API_URL"), "token": os.getenv("MILVUS_API_KEY")},
    #drop_old=True,  # Drop the old Milvus collection if it exists
    auto_id=True,
)
```

```python
query = "Pixar公司是做什么的?"
docs = vector_db.similarity_search(query)
```

```python
print(docs[0].page_content)
```

```plain
During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。
```



### 总结
+ 下面是 Chroma、Weaviate、Qdrant 和 Milvus 四个向量数据库的功能对比

| 功能/特性 | Chroma | Weaviate | Qdrant | Milvus |
| --- | --- | --- | --- | --- |
| 数据模型 | 向量 + 元数据 | 向量 + 元数据 | 向量 + 元数据 | 向量 + 元数据 |
| 支持的索引类型 | HNSW | HNSW, IVF, Flat | HNSW | IVF, HNSW, ANNOY, Flat |
| 扩展性 | 高 | 高 | 高 | 高 |
| 实时性 | 实时更新 | 实时更新 | 实时更新 | 实时更新 |
| 多样化查询 | 向量相似性搜索 | 向量相似性搜索 + 混合查询 | 向量相似性搜索 | 向量相似性搜索 + 混合查询 |
| 分布式架构 | 是 | 是 | 是 | 是 |
| 支持的语言 | Python, JavaScript | Python, Java, Go, TypeScript | Python, Go | Python, Java, Go, Node.js |
| 社区支持 | 活跃 | 活跃 | 活跃 | 活跃 |
| 开源许可证 | Apache 2.0 | BSD-3-Clause | Apache 2.0 | Apache 2.0 |
| 部署选项 | 本地, 云 | 本地, 云 | 本地, 云 | 本地, 云 |
| 额外功能 | 数据版本控制 | 知识图谱集成, 模型管理 | 集成向量处理工具 | 数据管理工具, 集成分析工具 |


这些数据库在功能和特性上各有优势，选择合适的数据库应根据具体的应用需求和技术栈来决定。

## FAISS, Pinecone, Lance Similarity search
### FAISS
#### Faiss介绍
[Facebook AI Similarity Search (Faiss /Fez/)](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) 是一个用于高效相似度搜索和密集向量聚类的库。它包含了在任意大小的向量集合中进行搜索的算法，甚至可以处理可能无法完全放入内存的向量集合。它还包含用于评估和参数调整的支持代码。

[Faiss ](https://faiss.ai/)官方文档：[https://faiss.ai/](https://faiss.ai/)

下面展示如何使用与 `FAISS` 向量数据库相关的功能。它将展示特定于此集成的功能。在学习完这些内容后，探索[相关的用例页面](http://www.aidoczh.com/langchain/v0.2/docs/how_to/#qa-with-rag)可能会很有帮助，以了解如何将这个向量存储作为更大链条的一部分来使用。

#### 设置
该集成位于 `langchain-community` 包中。我们还需要安装 `faiss` 包本身。我们还将使用 OpenAI 进行嵌入，因此需要安装这些要求。我们可以使用以下命令进行安装：

```bash
pip install -U langchain-community faiss-cpu langchain-openai tiktoken
```

请注意，如果您想使用启用了 GPU 的版本，也可以安装 `faiss-gpu`。

设置 [LangSmith](https://smith.langchain.com/) 以获得最佳的可观测性也会很有帮助（但不是必需的）。

```python
# os.environ["LANGCHAIN_TRACING_V2"] = "true"
# os.environ["LANGCHAIN_API_KEY"] = ""
```

#### 导入
在这里，我们将文档导入到向量存储中。

```python
#示例：faiss_search.py
# 如果您需要使用没有 AVX2 优化的 FAISS 进行初始化，请取消下面一行的注释
# os.environ['FAISS_NO_AVX2'] = '1'
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
loader = TextLoader("../../resource/knowledge.txt", encoding="UTF-8")
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)
docs = text_splitter.split_documents(documents)
embeddings = OpenAIEmbeddings()
db = FAISS.from_documents(docs, embeddings)
print(db.index.ntotal)
```

```plain
16
```

#### 查询
现在，我们可以查询向量存储。有几种方法可以做到这一点。最常见的方法是使用 `similarity_search`。

```python
#示例：faiss_search.py
query = "Pixar公司是做什么的?"
docs = db.similarity_search(query)
```

```python
print(docs[0].page_content)
```

```plain
During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。
```

#### 作为检索器
我们还可以将向量存储转换为 [Retriever](http://www.aidoczh.com/langchain/v0.2/docs/how_to/#retrievers) 类。这使我们能够轻松地在其他 LangChain 方法中使用它，这些方法主要用于检索器。

```python
#示例：faiss_retriever.py
retriever = db.as_retriever()
docs = retriever.invoke(query)
```

```python
print(docs[0].page_content)
```

```plain
During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。
```

#### 带分数的相似度搜索
还有一些 FAISS 特定的方法。其中之一是 `similarity_search_with_score`，它允许您返回文档以及查询与它们之间的距离分数。返回的距离分数是 L2 距离。因此，得分越低越好。

```python
#示例：faiss_similarity.py
#返回文档以及查询与它们之间的距离分数。返回的距离分数是 L2 距离。因此，得分越低越好。
docs_and_scores = db.similarity_search_with_score(query)
print(docs_and_scores)
#还可以使用`similarity_search_by_vector`来搜索与给定嵌入向量相似的文档，该函数接受一个嵌入向量作为参数，而不是字符串。
embedding_vector = embeddings.embed_query(query)
docs_and_scores = db.similarity_search_by_vector(embedding_vector)
print(docs_and_scores)
```

```python
[(Document(metadata={'source': '../../resource/knowledge.txt'}, page_content="During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.\n在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。"), 0.3155345), (Document(metadata={'source': '../../resource/knowledge.txt'}, page_content='I was lucky – I found what I loved to do early in life. Woz and I started Apple in my parents garage when I was 20. We worked hard, and in 10 years Apple had grown from just the two of us in a garage into a billion company with over 4000 employees. We had just released our finest creation - the Macintosh - a year earlier, and I had just turned 30. And then I got fired. How can you get fired from a company you started? Well, as Apple grew we hired someone who I thought was very talented to run the company with me, and for the first year or so things went well. But then our visions of the future began to diverge and eventually we had a falling out. When we did, our Board of Directors sided with him. So at 30 I was out. And very publicly out. What had been the focus of my entire adult life was gone, and it was devastating.\n我非常幸运，因为我在很早的时候就找到了我钟爱的东西。沃兹和我在二十岁的时候就在父母的车库里面开创了苹果公司。我们工作得很努力，十年之后，这个公司从那两个车库中的穷光蛋发展到了超过四千名的雇员、价值超过二十亿的大公司。在公司成立的第九年，我们刚刚发布了最好的产品，那就是 Macintosh。我也快要到三十岁了。在那一年，我被炒了鱿鱼。你怎么可能被你自己创立的公司炒了鱿鱼呢？嗯，在苹果快速成长的时候，我们雇用了一个很有天分的家伙和我一起管理这个公司，在最初的几年，公司运转的很好。但是后来我们对未来的看法发生了分歧, 最终我们吵了起来。当争吵不可开交的时候，董事会站在了他的那一边。所以在三十岁的时候，我被炒了。在这么多人的眼皮下我被炒了。在而立之年，我生命的全部支柱离自己远去，这真是毁灭性的打击。'), 0.44481623), (Document(metadata={'source': '../../resource/knowledge.txt'}, page_content="I really didn't know what to do for a few months. I felt that I had let the previous generation of entrepreneurs down - that I had dropped the baton as it was being passed to me. I met with David Packard and Bob Noyce and tried to apologize for screwing up so badly. I was a very public failure, and I even thought about running away from the valley. But something slowly began to dawn on me – I still loved what I did. The turn of events at Apple had not changed that one bit. I had been rejected, but I was still in love. And so I decided to start over.\n在最初的几个月里，我真是不知道该做些什么。我把从前的创业激情给丢了，我觉得自己让与我一同创业的人都很沮丧。我和 David Pack 和 Bob Boyce 见面，并试图向他们道歉。我把事情弄得糟糕透顶了。但是我渐渐发现了曙光，我仍然喜爱我从事的这些东西。苹果公司发生的这些事情丝毫的没有改变这些，一点也没有。我被驱逐了，但是我仍然钟爱它。所以我决定从头再来。\n\nI didn't see it then, but it turned out that getting fired from Apple was the best thing that could have ever happened to me. The heaviness of being successful was replaced by the lightness of being a beginner again, less sure about everything. It freed me to enter one of the most creative periods of my life.\n我当时没有觉察，但是事后证明，从苹果公司被炒是我这辈子发生的最棒的事情。因为，作为一个成功者的极乐感觉被作为一个创业者的轻松感觉所重新代替：对任何事情都不那么特别看重。这让我觉得如此自由，进入了我生命中最有创造力的一个阶段。"), 0.46826816), (Document(metadata={'source': '../../resource/knowledge.txt'}, page_content="I'm pretty sure none of this would have happened if I hadn't been fired from Apple. It was awful tasting medicine, but I guess the patient needed it. Sometimes life hits you in the head with a brick. Don't lose faith. I'm convinced that the only thing that kept me going was that I loved what I did. You've got to find what you love. And that is as true for your work as it is for your lovers. Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the only way to do great work is to love what you do. If you haven't found it yet, keep looking. Don't settle. As with all matters of the heart, you'll know when you find it. And, like any great relationship, it just gets better and better as the years roll on. So keep looking until you find it. Don't settle.\n我可以非常肯定,如果我不被苹果公司开除的话，这其中一件事情也不会发生的。这个良药的味道实在是太苦了，但是我想病人需要这个药。有些时候，生活会拿起一块砖头向你的脑袋上猛拍一下。不要失去信心，我很清楚唯一使我一直走下去的，就是我做的事情令我无比钟爱。你需要去找到你所爱的东西，对于工作是如此，对于你的爱人也是如此。你的工作将会占据生活中很大的一部分。你只有相信自己所做的是伟大的工作，你才能怡然自得。如果你现在还没有找到，那么继续找、不要停下来、全心全意的去找，当你找到的时候你就会知道的。就像任何真诚的关系，随着岁月的流逝只会越来越紧密。所以继续找，直到你找到它，不要停下来。\n\nMy third story is about death.\n我的第三个故事是关于死亡的。"), 0.4740282)]
```

#### 保存和加载
您还可以保存和加载 FAISS 索引。这样做很有用，因为您不必每次使用时都重新创建它。

```python
#示例：faiss_save.py
#保存索引
db.save_local("faiss_index")
#读取索引
new_db = FAISS.load_local("faiss_index", embeddings,allow_dangerous_deserialization=True)
docs = new_db.similarity_search(query)
```

```python
docs[0]
```

```plain
page_content='During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。' metadata={'source': '../../resource/knowledge.txt'}
```



### Pinecone
#### Pinecone介绍
[Pinecone](https://docs.pinecone.io/docs/overview) (/ˈpaɪnˌkon/ n. 松果；松球)是一个功能广泛的向量数据库。

官方文档：[https://docs.pinecone.io/guides/get-started/quickstart](https://docs.pinecone.io/guides/get-started/quickstart)

下面展示了如何使用与 `Pinecone` 向量数据库相关的功能。

设置以下环境变量以便在本文档中进行操作：

+ `OPENAI_API_KEY`：您的 OpenAI API 密钥，用于使用 `OpenAIEmbeddings`

```python
%pip install --upgrade --quiet  \
    langchain-pinecone \
    langchain-openai \
    langchain \
    pinecone-notebooks
```

配置PINECONE_API_KEY 环境变量

```powershell
setx PINECONE_API_KEY ""
```

![](https://cdn.nlark.com/yuque/0/2024/png/2424104/1724049661614-25865098-3e21-4cb5-a9c8-e2caeb852032.png)

首先，让我们将我们的文本库拆分成分块的 `docs`。

```python
#示例：pinecone_search.py
from langchain_community.document_loaders import TextLoader
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
loader = TextLoader("../../resource/knowledge.txt",encoding="UTF-8")
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)
docs = text_splitter.split_documents(documents)
embeddings = OpenAIEmbeddings()
```

新创建的 API 密钥已存储在 `PINECONE_API_KEY` 环境变量中。我们将使用它来设置 Pinecone 客户端。

```python
import os
pinecone_api_key = os.environ.get("PINECONE_API_KEY")
pinecone_api_key
import time
from pinecone import Pinecone, ServerlessSpec
pc = Pinecone(api_key=pinecone_api_key)
```

接下来，让我们连接到您的 Pinecone 索引。如果名为 `index_name` 的索引不存在，将会被创建。

```python
import time
index_name = "langchain-index"  # 如果需要，可以更改
existing_indexes = [index_info["name"] for index_info in pc.list_indexes()]
if index_name not in existing_indexes:
    pc.create_index(
        name=index_name,
        dimension=1536,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
    )
    while not pc.describe_index(index_name).status["ready"]:
        time.sleep(1)
index = pc.Index(index_name)
```

现在我们的 Pinecone 索引已经设置好，我们可以使用 `PineconeVectorStore.from_documents` 将这些分块的文档作为内容进行更新。

```python
from langchain_pinecone import PineconeVectorStore
docsearch = PineconeVectorStore.from_documents(docs, embeddings, index_name=index_name)
```

```python
query = "Pixar"
docs = docsearch.similarity_search(query)
print(docs[0].page_content)
```

```plain
During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。
```

查看index创建：[https://app.pinecone.io](https://app.pinecone.io/organizations/-O3c52_oskiguJEqQubV/projects/f087a26f-d581-4af3-a628-2a13ead9fd7c/indexes)

### Lance
#### [LanceDB](https://lancedb.com/)介绍
[Lance](https://lancedb.com/)（ /læns/ 长矛；执矛战士；[医]柳叶刀）是一个基于持久存储构建的用于向量搜索的开源数据库，极大地简化了嵌入式的检索、过滤和管理。完全开源。

官网：[https://lancedb.com/](https://lancedb.com/)

官方文档：[https://lancedb.github.io/lancedb/basic/](https://lancedb.github.io/lancedb/basic/)

下面展示如何使用与 `LanceDB` 向量数据库相关的功能，基于 Lance 数据格式。

```python
! pip install -U langchain-openai
```

```python
! pip install lancedb
```

```python
#示例：lance_search.py
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import LanceDB
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter

loader = TextLoader("../../resource/knowledge.txt", encoding="UTF-8")
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)
documents = text_splitter.split_documents(documents)
embeddings = OpenAIEmbeddings()
```

#### 向量存储
```python
docsearch = LanceDB.from_documents(documents, embeddings)
query = "Pixar公司是做什么的?"
docs = docsearch.similarity_search(query)
print(docs[0].page_content)
```

```plain
During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I retuned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.
在接下来的五年里, 我创立了一个名叫 NeXT 的公司，还有一个叫Pixar的公司，然后和一个后来成为我妻子的优雅女人相识。Pixar 制作了世界上第一个用电脑制作的动画电影——“”玩具总动员”，Pixar 现在也是世界上最成功的电脑制作工作室。在后来的一系列运转中，Apple 收购了NeXT，然后我又回到了苹果公司。我们在NeXT 发展的技术在 Apple 的复兴之中发挥了关键的作用。我还和 Laurence 一起建立了一个幸福的家庭。
```

```python
print(docs[0].metadata)
```

```python
{'source': '../../resource/knowledge.txt'}
```

---

此外，要探索表格，可以将其加载到数据框中或将其保存在 csv 文件中：

```python
tbl = docsearch.get_table()
print("tbl:", tbl)
pd_df = tbl.to_pandas()
pd_df.to_csv("docsearch.csv", index=False)
```

```python
tbl: LanceTable(connection=LanceDBConnection(D:\tmp\lancedb), name="vectorstore")
```



### 总结
下面是 Pinecone、FAISS 和 Lance 三个向量数据库的功能对比表格：

| 功能/特性 | Pinecone | FAISS | Lance |
| --- | --- | --- | --- |
| 数据模型 | 向量 + 元数据 | 向量 | 向量 + 元数据 |
| 支持的索引类型 | HNSW | IVF, HNSW, PQ, OPQ | HNSW |
| 扩展性 | 高 | 中 | 高 |
| 实时性 | 实时更新 | 批量处理 | 实时更新 |
| 多样化查询 | 向量相似性搜索 | 向量相似性搜索 | 向量相似性搜索 |
| 分布式架构 | 是 | 否 | 是 |
| 支持的语言 | Python, JavaScript, Go | Python, C++ | Python |
| 社区支持 | 活跃 | 活跃 | 新兴 |
| 开源许可证 | 专有 | MIT | Apache 2.0 |
| 部署选项 | 云 | 本地 | 本地, 云 |
| 额外功能 | 自动扩展, 数据管理工具 | 高度优化的搜索性能 | 数据版本控制, 集成分析工具 |


这些数据库在功能和特性上各有优势，选择合适的数据库应根据具体的应用需求和技术栈来决定。


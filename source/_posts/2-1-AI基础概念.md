---
title: AI基础概念
date: 2025-01-12 15:35:21

categories:
  - LLM
tags:
  - AI
  - DL
  - ML
  - LLM




---
什么是AI（Artificial intelligence 人工智能）：通过机器学习，深度学习等算法，使得系统具备学习、推理、自我修正和解决问题等功能。
- 语言
- 语音
- 视觉
- 多模态感知和决策

*意图识别；情绪识别；表情识别*





## NL 自然语言

### NLP 自然语言处理

自然语言处理（Natural Language Processing, NLP）是人工智能的一个子领域，致力于实现计算机对人类语言的理解、和生成。包含从*文本处理*到*语音识别*的广泛任务。

例子:
- 文本分类: 电子邮件过滤系统可以使用NLP来自动将邮件分类为“垃圾邮件”或“非垃圾邮件”。
- 情感分析: 社交媒体监控工具可以使用NLP来分析用户评论的情感倾向（正面、负面或中性）。


### NLU 自然语言理解

自然语言理解（Natural Language Understanding）是NLP的一个子领域，专注于使计算机能够理解人类语言的含义。NLU涉及语义分析、意图识别、实体识别等任务。

例子:
- 意图识别: 当对语音助手说“帮我订一张明天去纽约的机票”，系统需要识别用户的意图是“订票”。
- 实体识别: 在同一句话中，系统需要识别出“纽约”是一个地名，“明天”是一个时间表达。


### NLG 自然语言生成

自然语言生成（Natural Language Generation）是NLP的另一个子领域，专注于计算机能生成人类的语言, 非常贴近真人说话的方式。NLG通常用于自动报告生成、内容创作等场景。
例子:
- 自动报告: 金融分析工具可以使用NLG来生成每日或每周的市场分析报告。
- 内容创作: 新闻自动写作系统可以根据输入的数据生成新闻文章，如体育比赛的赛后报道。


#### 具体例子

假设智能语音助手（如Siri或Alexa）
1. 用户输入: 明天的天气怎么样？
2. NLP: 
    - 语音识别: 将语言转换为文本.
    - 文本预处理: 来清理和规范化文本,去除空格或标点.
3. NLU: 
    - 意图识别: 首先识别用户意图"询问天气". 
    - 实体识别: 再识别出"明天"是时间相关实体.
4. 数据处理: 系统查询天气数据库, 获取"明天"的天气信息.
5. NLG: 
    - 生成文本: 将查询结果转换为自然语言文本:"明天是晴天,最高10度,最低-5度,要注意保暖哦". 
    - 语音合成: 将文本转换为语音,并播放给用户听.


## 监督学习(Supervised Learning)
监督学习是一种机器学习方法，模型通过已知的输入和输出数据进行训练，直到模型能够准确地匹配输入和输出的关系。

### 分类（Classification）
分类任务是将输入数据分为离散的类别。
- 例子：垃圾邮件过滤。给定一封电子邮件，模型需要判断这封邮件是垃圾邮件（spam）还是正常邮件（ham）。

### 回归（Regression）
回归任务是预测连续的数值输出。
- 例子：房价预测。根据特征（如房子的面积、位置等），模型预测房子的价格。

### 关联规则（Association Rule）
关联规则是寻找数据中不同项之间的关系或模式。
- 例子：购物篮分析。超市可以通过关联规则发现哪些商品常常一起被购买，比如“如果顾客买了面包和黄油，他们也很可能会买牛奶”。



## 无监督学习（Unsupervised Learning）

无监督学习是一种机器学习方法，模型在没有标签数据（即没有输入和输出配对）的情况下，通过数据内部的结构进行学习。

### 聚类（Clustering）
聚类任务是将数据分成不同的组，每个组中的数据项彼此相似。
- 例子：客户细分。根据购买行为的数据，商业可以将客户分成不同的群体，比如“大宗购买者”、“偶尔购买者”等。


## 强化学习（Reinforcement Learning）

强化学习是一种机器学习方法，其中一个**智能体（Agent**通过与**环境（Environment）**互动，以试错的方式学习如何完成任务或达到目标。

>个人感觉和Stochastic Optimisation很像，如果学过会很快理解这个部分。

### 核心概念：
1. 状态（States）：状态是对当前环境的一种描述。在任何时刻，Agent所处的状态反映了当前的环境情况。
  - 例子：在一个迷宫游戏中，state可以是agent当前所在的位置；在围棋中，状态就是棋盘上每颗棋子的布局。
2. 奖励（Reward）：奖励是对agent在某个state下采取某个动作后的反馈，它可以是**正的**（奖励）或**负的**（惩罚）。
  - 例子：在迷宫游戏中，如果智能体走到正确的方向，可以获得正的奖励（例如+10分）；如果撞到墙壁，可能会获得**负的奖励**（例如-10分，也就是惩罚）。
3. 智能体（Agent）：智能体是执行动作并接收reward的决策者。agent通过不断地选择动作来改变其state，从而尝试最大化累计reward。
  - 例子：在自动驾驶汽车中，智能体就是控制汽车行驶的算法；在游戏中，智能体就是玩家控制的角色或者对手AI。

### 强化学习的过程：
1. 观察：agent观察当前的state。
2. 选择动作：根据当前state，agent选择一个动作。这个动作可能基于之前的学习，也可能是一个随机选择。
3. 执行动作：agent执行所选择的动作，环境随之发生改变。
4. 获取反馈：环境向agent提供执行该动作后的新state和即时reward。
5. 更新策略：agent根据reward更新其策略，使其在未来选择更优的动作，以获得更多的累计reward。

### 一个简单的例子：
玩具汽车学习走迷宫
1. 状态（States）：玩具汽车在迷宫中的位置，例如（2, 3）代表在迷宫中第二行第三列的位置。
2. 动作（Actions）：玩具汽车可以前进的方向，例如上、下、左、右。
3. 奖励（Reward）：如果玩具汽车朝着出口前进，它获得一个正的奖励（+10分）；如果撞到死胡同或墙，则获得负的奖励（-10分）。
4. 智能体（Agent）：控制玩具汽车的AI

## 机器学习效果评估

### 欠拟合 (Under-fitting)
欠拟合是指模型过于简单，无法捕捉到训练数据中的模式和特征，导致在训练数据和新数据上的表现都很差。
- **实际例子**：在房价预测问题中，你只用房子的面积一个特征来预测价格，而忽略了位置、房龄、装修等重要特征，导致模型无法准确预测房价

### 最佳拟合 (Optimal-fitting)
最佳拟合是指模型恰当地捕捉到了训练数据中的模式和特征，同时也能很好地应用于新数据。这种情况下，模型在训练数据和测试数据上都有良好的表现。
- **实际例子**：在房价预测问题中，你考虑了多个重要特征（如面积、位置、房龄、装修等），模型能够准确预测训练数据中的房价，并在新数据上表现也很好。

### 过拟合 (Over-fitting)
过拟合是指模型过于复杂，过度地记住了训练数据中的每一个细节和噪声，从而失去了对新数据的泛化能力。过拟合的模型在训练数据上表现很好，但在新数据上表现较差。
- **实际例子**：在房价预测问题中，你不仅使用了面积、位置、房龄、装修等特征，还加入了一些不相关的特征（如前几天是否下过雨），模型在训练数据上表现非常好，但在新数据上预测效果很差。


### 总结：
1. 欠拟合 (Under-fitting)：模型太简单，不能很好地捕捉数据中的模式。
  - 简单例子：用直线拟合“U”形数据。
  - 实际例子：房价预测中只用面积一个特征。
2. 最佳拟合 (Optimal-fitting)：模型恰到好处，既能很好地拟合训练数据，也能对新数据有良好表现。
  - 简单例子：用合适的二次曲线拟合“U”形数据。
  - 实际例子：房价预测中使用了多个重要特征。
3. 过拟合 (Over-fitting)：模型太复杂，过度记住了训练数据，无法泛化到新数据。
  - 简单例子：用复杂的高次多项式拟合“U”形数据，过度拟合了每个数据点。
  - 实际例子：房价预测中加入了很多不相关特征，结果在新数据上效果不好。
总之，目标是找到让模型最佳拟合训练数据和测试数据的平衡点，既不过于简单也不过于复杂。



## 深度学习 (Deep Learning)
深度学习是一种机器学习方法，它利用多层神经网络进行复杂的数据处理和模式识别。在理解深度学习时，我们需要了解神经网络的三种关键层：
- 输入层（Input Layer）: 接收原始数据.
- 隐藏层（Hidden Layer）: 提取和转换输入数据的特征。
- 输出层（Output Layer）: 给出预测结果。

通过这些层的协同工作，神经网络能够从原始数据中学习模式，并对新数据进行准确的预测或分类。神经网络（Neural Network）是模仿人脑工作原理的一种算法，由多个互相连接的节点（也叫神经元）组成。这些节点被组织成不同的层，通过层与层之间的连接和权重调整来处理数据。

### 输入层 (Input Layer)
输入层是神经网络的第一个层，它接收原始的数据输入。这些输入可以是图像的像素值、文本的词向量或其他形式的数据。输入层的节点（或神经元）数目取决于输入数据的特征数。
- 例子：
  - **图像分类：** 如果你有一张28x28像素的灰度图像作为输入，输入层将有28×28=784个节点，每个节点代表一个像素值。
  - **房价预测：** 如果你有五个特征（如面积、位置、房龄等），输入层将有5个节点，每个节点代表一个特征值。

### 隐藏层 (Hidden Layer)
**隐藏层**位于输入层和输出层之间，负责对输入数据进行特征提取和变换。隐藏层可以有一层或多层，称为“深度”正是因为有许多隐藏层。每个隐藏层通过与前一层和后一层的连接（权重和偏置）来传递信息。

- 例子：
  - **图像分类：** 何将28x28像素的输入映射到更加抽象的特征层，如第一层可能识别边缘，第二层可能识别更复杂的形状。
  - **房价预测：** 隐藏层可以捕捉输入特征的复杂非线性关系，帮助模型准确预测房价。

### 输出层 (Output Layer)
**输出层**是神经网络的最后一层，它给出模型的最终预测结果。输出层的节点数目和类型取决于具体的任务。
- 例子：
  - **图像分类：** 如果你要把图像分类为10个类别（如手写数字0-9），输出层将有10个节点，每个节点代表一个类别的概率。
  - **房价预测：** 如果你需要预测房价，输出层将有一个节点，它输出房价的预测值。

### 综合例子
#### 任务：图像分类
1. **输入层**：假设我们分类的是28x28像素的手写数字图像。
    - **输入层节点数：** 784个节点，每个节点对应一个像素值。
2. **隐藏层**：假设有两层隐藏层。
    - **第一隐藏层：** 提取简单特征（如边缘），设有128个节点。
    - **第二隐藏层：** 提取更复杂的特征（如更高层次的形状），设有64个节点。
3. **输出层**：假设分类为10个类别（数字0到9）。
    - **输出层节点数：** 10个节点，每个节点代表图像属于某个数字类别的概率。

#### 任务：房价预测
1. **输入层：** 假设预测房价时用五个特征：面积、位置、房龄、房型、市场状况。
    - **输入层节点数：** 5个节点，每个节点代表一个特征。
2. **隐藏层：** 假设有一层隐藏层。
    - **隐藏层：** 捕捉输入特征之间的复杂关系，设有10个节点。
3. **输出层：** 输出预测的房价。
    - **输出层节点数：** 1个节点，表示预测的房价。










 

## 神经网络 (Neural Networks)

## CNN（卷积神经网络）

## RNN（循环神经网络)

## Transformer

## BERT

## GPT（生成式预训练）

## 向量数据库

## 嵌入（Embeddings）

## LLM（大语言模型）

## Model Size

## OpenAI 简介









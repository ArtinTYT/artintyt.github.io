---
title: 1.从全连接层到卷积
date: 2025-04-18 14:32:10
tags:
    - Deep_Learning
    - CNNs
categories:
    - CNNs
---
# 1. 从全连接层到卷积

## 1. 介绍

- **全连接层（Fully Connected Layer, FC Layer）**
	- **定义**：全连接层是最基础的神经网络层，**每个输入都和每个输出节点相连**，每条连接都有独立的权重。
	- **数学形式**：
	    $$\mathbf{y} = \mathbf{W}\mathbf{x} + \mathbf{b}$$
	    其中 $\mathbf{W}$ 是 $m \times n$ 的权重矩阵，$\mathbf{b}$ 是偏置项。
        
- 卷积（Convolution）层
	- **定义**：卷积是一种重要的线性运算，广泛用于信号和图像处理中。它通过一个小的“卷积核”（滤波器）在输入上滑动，局部地与输入片段相乘并求和，从而提取局部特征。
	- **数学定义**：
	    - **连续情形**：两个函数 $f$、$g$ 的卷积定义为
	        $$(f * g)(x) = \int f(z)g(x-z)dz$$
	    - **离散情形**：对于序列（如一维数组）
	        $$(f * g)(i) = \sum_a f(a)g(i-a)$$
	    - **二维情形**（如图像）：
	        $$(f * g)(i, j) = \sum_a \sum_b f(a, b)g(i-a, j-b)$$
	- **实际深度学习实现**：通常使用的是**互相关（cross-correlation）**，即没有对卷积核做翻转：
	    $$(f * g)(i, j) = \sum_a \sum_b f(a, b)g(i+a, j+b)$$

## 2. 动机

-  全连接层的局限性
	- **参数爆炸**：输入是 $1000 \times 1000$ 像素，输出1000单元，参数量高达10亿，训练与存储极其低效。
	- **丢失空间结构**：图像被拉平成向量，丢失了像素间的空间关系，无法有效捕捉局部特征（如边缘、纹理等）。
	
- 设计视觉神经网络的两大原则：
	1. **平移不变性 (Translation Invariance)**
	    - 特征无论出现在图像何处都应能被检测到。
	    - 实现方式：**参数共享**，即同一个卷积核在整张图像滑动检测特征。
	2. **局部性 (Locality)**
	    - 每个输出神经元只与输入的局部区域（感受野）相关。
	    - 实现方式：卷积核大小有限（如 $3\times3$），远距离像素不参与加权。

## 3. 从全连接到卷积的数学推演

1. **全连接层形式**：
	- 将输入和输出变形为矩阵（宽度，高度）。
	- 将权重变形为 4-D 张量 $(h, w) \to (h', w')$；核矩阵大小：超参数。
	    $$h_{i,j} = \sum_{k,l} w_{i,j,k,l} \cdot x_{k,l}$$
2. **重索引权重**：
	- 可重写为
	    $$h_{i,j} = \sum_{a,b} v_{i,j,a,b} \cdot x_{i+a, j+b}$$
	- $v_{i,j,a,b} = w_{i,j,i+a,j+b}$

3. **引入平移不变性**：
	- 要求参数$v$ 不依赖于位置 $(i,j)$ ，令 $v_{i,j,a,b} = v_{a,b}$，即参数共享。
	    $$h_{i,j} = \sum_{a,b} v_{a,b} \cdot x_{i+a,j+b}$$​
	- **数学意义**：是互相关（cross-correlation），虽然我们叫**卷积**。

4. **引入局部性**：
	- 限定 $a, b$ 取值范围（如 $|a|, |b| \leq \Delta$），只与邻域有关：
	    $$h_{i,j} = \sum_{a=-\Delta}^{\Delta} \sum_{b=-\Delta}^{\Delta} v_{a,b} \cdot x_{i+a,j+b}$$
	- $\Delta$ 控制局部范围，当 $|a|, |b| > \Delta$ 时，令 $v_{a,b} = 0$。

## 4. 总结

- 全连接层：参数量巨大，难以处理高维图像，也无法捕捉空间结构。
- 卷积层：通过参数共享和局部连接，极大减少参数，提升效率。
- 平移不变性：同一特征无论出现在何处都能被检测。
- 局部性：每个输出只关注输入的局部区域（感受野）。
- 卷积为深度学习视觉任务奠定了高效、可扩展的结构基础。


## 参考资料

- [李沐《动手学深度学习》：6.1. 从全连接层到卷积](https://zh.d2l.ai/chapter_convolutional-neural-networks/why-conv.html)
- [Bilibili：从全连接层到卷积](https://www.bilibili.com/video/BV1L64y1m7Nh)